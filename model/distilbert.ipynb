{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girish/.local/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libjpeg.so.8: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:00:14.240848Z",
     "iopub.status.busy": "2024-11-14T07:00:14.240521Z",
     "iopub.status.idle": "2024-11-14T07:01:05.190455Z",
     "shell.execute_reply": "2024-11-14T07:01:05.189438Z",
     "shell.execute_reply.started": "2024-11-14T07:00:14.240816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 07:18:14.008380: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-15 07:18:14.014671: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-15 07:18:14.143936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 07:18:14.143993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 07:18:14.163401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 07:18:14.203250: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-15 07:18:14.204693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-15 07:18:16.250155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-15 07:18:17.696478: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-11-15 07:18:17.696938: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /xla/service/gpu/compiled_programs_count. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-11-15 07:18:17.699056: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_executions. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-11-15 07:18:17.699082: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_execution_time_usecs. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-11-15 07:18:18.858160: I itex/core/wrapper/itex_gpu_wrapper.cc:38] Intel Extension for Tensorflow* GPU backend is loaded.\n",
      "2024-11-15 07:18:18.860247: I external/local_xla/xla/pjrt/pjrt_api.cc:67] PJRT_Api is set for device type xpu\n",
      "2024-11-15 07:18:18.860284: I external/local_xla/xla/pjrt/pjrt_api.cc:72] PJRT plugin for XPU has PJRT API version 0.33. The framework PJRT API version is 0.34.\n",
      "2024-11-15 07:18:18.953440: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:134] Selected platform: Intel(R) Level-Zero\n",
      "2024-11-15 07:18:18.953639: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:159] number of sub-devices is zero, expose root device.\n",
      "2024-11-15 07:18:18.957604: I external/xla/xla/service/service.cc:168] XLA service 0x2b935d10 initialized for platform SYCL (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-15 07:18:18.957623: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): Intel(R) Graphics [0x7d55], <undefined>\n",
      "2024-11-15 07:18:18.957818: I itex/core/devices/gpu/itex_gpu_runtime.cc:130] Selected platform: Intel(R) Level-Zero\n",
      "2024-11-15 07:18:18.957841: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n",
      "2024-11-15 07:18:18.960407: I external/intel_xla/xla/pjrt/se_xpu_pjrt_client.cc:97] Using BFC allocator.\n",
      "2024-11-15 07:18:18.960429: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 13923267379 bytes on device 0 for BFCAllocator.\n",
      "2024-11-15 07:18:18.962982: I external/local_xla/xla/pjrt/pjrt_c_api_client.cc:119] PjRtCApiClient created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,DistilBertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:05.192261Z",
     "iopub.status.busy": "2024-11-14T07:01:05.191550Z",
     "iopub.status.idle": "2024-11-14T07:01:06.733580Z",
     "shell.execute_reply": "2024-11-14T07:01:06.732713Z",
     "shell.execute_reply.started": "2024-11-14T07:01:05.192231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the cleaned training data\n",
    "# train_df = pd.read_csv(\"train_cleaned_consolidated.csv\")\n",
    "train_df = pd.read_csv(\"new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13176, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mostly False</td>\n",
       "      <td>Six out of 10 of the highest unemployment rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>No Democratic campaign for (Fla.) governor has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Says Ron Paul insisted FEMA should be shut dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mostly False</td>\n",
       "      <td>Says Hillary Clinton has \"been in office and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>In 1916, the U.S. government predicted that by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                           combined\n",
       "0  Mostly False  Six out of 10 of the highest unemployment rate...\n",
       "1          True  No Democratic campaign for (Fla.) governor has...\n",
       "2          True  Says Ron Paul insisted FEMA should be shut dow...\n",
       "3  Mostly False  Says Hillary Clinton has \"been in office and i...\n",
       "4         False  In 1916, the U.S. government predicted that by..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mostly False', 'True', 'False', 'Mostly True', 'Unverified/Mixed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "False               8383\n",
       "True                4320\n",
       "Unverified/Mixed     473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"] = train_df[\"label\"].replace({\"Mostly False\": \"False\", \"Mostly True\": \"True\"})\n",
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "False    8383\n",
       "True     4320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[train_df[\"label\"] != \"Unverified/Mixed\"]\n",
    "train_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18603/21520905.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[\"label\"] = train_df[\"label\"].replace({\"True\": 1, \"False\": 0})\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the training labels and transform the test labels\n",
    "train_df[\"label\"] = train_df[\"label\"].replace({\"True\": 1, \"False\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4320\n",
       "0    4320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with 'False' label\n",
    "false_df = train_df[train_df[\"label\"] == 0]\n",
    "\n",
    "# Randomly sample 4063 rows from the 'False' label\n",
    "false_to_remove = false_df.sample(n=4063, random_state=42)  # You can change the random_state for different randomization\n",
    "\n",
    "# Remove those rows from the original DataFrame\n",
    "train_df = train_df.drop(false_to_remove.index)\n",
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (stratified)\n",
    "train_data, test_data = train_test_split(train_df, test_size=0.2, stratify=train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:06.758256Z",
     "iopub.status.busy": "2024-11-14T07:01:06.758000Z",
     "iopub.status.idle": "2024-11-14T07:01:07.427672Z",
     "shell.execute_reply": "2024-11-14T07:01:07.426783Z",
     "shell.execute_reply.started": "2024-11-14T07:01:06.758229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:07.429145Z",
     "iopub.status.busy": "2024-11-14T07:01:07.428849Z",
     "iopub.status.idle": "2024-11-14T07:01:08.031757Z",
     "shell.execute_reply": "2024-11-14T07:01:08.030929Z",
     "shell.execute_reply.started": "2024-11-14T07:01:07.429116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:08.033061Z",
     "iopub.status.busy": "2024-11-14T07:01:08.032789Z",
     "iopub.status.idle": "2024-11-14T07:01:08.036910Z",
     "shell.execute_reply": "2024-11-14T07:01:08.036239Z",
     "shell.execute_reply.started": "2024-11-14T07:01:08.033034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the text column\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"combined\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:08.038047Z",
     "iopub.status.busy": "2024-11-14T07:01:08.037807Z",
     "iopub.status.idle": "2024-11-14T07:01:17.989618Z",
     "shell.execute_reply": "2024-11-14T07:01:17.988848Z",
     "shell.execute_reply.started": "2024-11-14T07:01:08.038022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bb04c3ecd94bd99531fdee05006976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2056adcdec8047798ab9b0ee96357c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1728 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:17.990998Z",
     "iopub.status.busy": "2024-11-14T07:01:17.990698Z",
     "iopub.status.idle": "2024-11-14T07:01:20.478843Z",
     "shell.execute_reply": "2024-11-14T07:01:20.478028Z",
     "shell.execute_reply.started": "2024-11-14T07:01:17.990968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the DistilBERT model for classification (2 labels in this case)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# model = model.to(\"xpu\")\n",
    "# model = ipex.optimize(model)\n",
    "# model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:20.481432Z",
     "iopub.status.busy": "2024-11-14T07:01:20.481086Z",
     "iopub.status.idle": "2024-11-14T07:01:26.687860Z",
     "shell.execute_reply": "2024-11-14T07:01:26.686700Z",
     "shell.execute_reply.started": "2024-11-14T07:01:20.481398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # output directory\n",
    "    eval_strategy=\"epoch\",  # evaluation strategy\n",
    "    learning_rate=2e-5,  # learning rate\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    num_train_epochs=1,  # number of epochs\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for logs\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:26.689207Z",
     "iopub.status.busy": "2024-11-14T07:01:26.688918Z",
     "iopub.status.idle": "2024-11-14T07:01:26.980336Z",
     "shell.execute_reply": "2024-11-14T07:01:26.979470Z",
     "shell.execute_reply.started": "2024-11-14T07:01:26.689177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,  # model to train\n",
    "    args=training_args,  # training arguments\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=test_dataset,  # evaluation dataset (test set)\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T07:01:26.981745Z",
     "iopub.status.busy": "2024-11-14T07:01:26.981438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 13:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=216, training_loss=0.4747846744678639, metrics={'train_runtime': 821.4059, 'train_samples_per_second': 8.415, 'train_steps_per_second': 0.263, 'total_flos': 915614659510272.0, 'train_loss': 0.4747846744678639, 'epoch': 1.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6336805555555556\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset[\"label\"], preds)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       864\n",
      "           1       0.64      0.62      0.63       864\n",
      "\n",
      "    accuracy                           0.63      1728\n",
      "   macro avg       0.63      0.63      0.63      1728\n",
      "weighted avg       0.63      0.63      0.63      1728\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert_classifier/tokenizer_config.json',\n",
       " 'bert_classifier/special_tokens_map.json',\n",
       " 'bert_classifier/vocab.txt',\n",
       " 'bert_classifier/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a detailed classification report\n",
    "report = classification_report(test_dataset[\"label\"], preds)\n",
    "print(f\"Classification Report:\\n{report}\")  # Save the trained model\n",
    "model.save_pretrained(\"bert_classifier\")\n",
    "tokenizer.save_pretrained(\"bert_classifier\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 6082630,
     "sourceId": 9901720,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30788,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
